import torch
import os
import csv
import argparse
from tqdm import tqdm
from torch.utils.data import DataLoader
from src.dataset import SharedBikeDataset, get_transform
from src.model import get_model

# --- å‚æ•°è®¾ç½® ---
parser = argparse.ArgumentParser()
# å‚æ•°åæ˜¯ --modelï¼Œæ‰€ä»¥è§£æåå­˜åœ¨ args.model ä¸­
parser.add_argument('--model', type=str, default='mb3_320', 
                    choices=['mb3_320', 'mb3_fpn', 'resnet50'], help='é€‰æ‹©è¦è®­ç»ƒçš„æ¨¡å‹')
args = parser.parse_args()

MODEL_NAME = args.model
# è‡ªåŠ¨æ£€æµ‹è®¾å¤‡
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
NUM_EPOCHS = 30 
BATCH_SIZE = 4
DATA_ROOT = './cycledata'
OUTPUT_DIR = f'./output/{MODEL_NAME}' 

def main():
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    print(f"ğŸš€ å¯åŠ¨è®­ç»ƒä»»åŠ¡: {MODEL_NAME}")
    print(f"ğŸ“‚ ç»“æœä¿å­˜è‡³: {OUTPUT_DIR}")
    print(f"âš™ï¸  ä½¿ç”¨è®¾å¤‡: {DEVICE}")
    
    # 1. å‡†å¤‡æ•°æ®
    train_loader = DataLoader(
        SharedBikeDataset(DATA_ROOT, split='train', transforms=get_transform()),
        batch_size=BATCH_SIZE, 
        shuffle=True, 
        collate_fn=lambda x: tuple(zip(*x)), 
        num_workers=4,  # å¤šè¿›ç¨‹è¯»å–
        pin_memory=True # åŠ é€Ÿè½¬GPU
    )
    
    # 2. åŠ è½½æ¨¡å‹ 
    # ã€é‡ç‚¹ã€‘è¿™é‡Œæ˜¯æ–¹æ¡ˆBï¼šnum_classes=2 (èƒŒæ™¯+è‡ªè¡Œè½¦)
    # ä¿®å¤ç‚¹ï¼šè¿™é‡ŒåŸæ¥å†™çš„æ˜¯ args.model_keyï¼Œç°åœ¨æ”¹ä¸º MODEL_NAME
    model = get_model(MODEL_NAME, num_classes=2, is_pretrained=True)
    model.to(DEVICE)
    
    # 3. ä¼˜åŒ–å™¨ä¸è°ƒåº¦å™¨
    params = [p for p in model.parameters() if p.requires_grad]
    optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)
    # æ¯3è½®è¡°å‡ä¸€æ¬¡å­¦ä¹ ç‡
    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)

    # 4. åˆå§‹åŒ–æ—¥å¿—
    log_path = os.path.join(OUTPUT_DIR, 'log.csv')
    with open(log_path, 'w', newline='') as f:
        csv.writer(f).writerow(['epoch', 'loss', 'lr'])

    best_loss = float('inf')
    
    # 5. å¼€å§‹è®­ç»ƒå¾ªç¯
    for epoch in range(1, NUM_EPOCHS + 1):
        model.train()
        ep_loss = 0
        
        # è¿›åº¦æ¡
        loop = tqdm(train_loader, desc=f"Epoch {epoch}/{NUM_EPOCHS} [{MODEL_NAME}]")
        
        for imgs, targets in loop:
            imgs = [img.to(DEVICE) for img in imgs]
            targets = [{k: v.to(DEVICE) for k, v in t.items()} for t in targets]
            
            # å‰å‘ä¼ æ’­è®¡ç®— Loss
            loss_dict = model(imgs, targets)
            losses = sum(loss for loss in loss_dict.values())
            
            # åå‘ä¼ æ’­
            optimizer.zero_grad()
            losses.backward()
            optimizer.step()
            
            # è®°å½•
            loss_val = losses.item()
            ep_loss += loss_val
            loop.set_postfix(loss=loss_val)
            
        avg_loss = ep_loss / len(train_loader)
        current_lr = optimizer.param_groups[0]['lr']
        
        # æ›´æ–°å­¦ä¹ ç‡
        scheduler.step()
        
        # å†™å…¥æ—¥å¿—
        with open(log_path, 'a', newline='') as f:
            csv.writer(f).writerow([epoch, avg_loss, current_lr])
            
        # ä¿å­˜æœ€ä½³æ¨¡å‹ (æ ¹æ® Loss)
        if avg_loss < best_loss:
            best_loss = avg_loss
            save_path = os.path.join(OUTPUT_DIR, 'best_model.pth')
            torch.save(model.state_dict(), save_path)
            # åŒæ—¶ä¹Ÿä¿å­˜ä¸€ä¸ªæœ€æ–°çš„ï¼Œé˜²æ­¢æ–­ç”µ
            torch.save(model.state_dict(), os.path.join(OUTPUT_DIR, 'last_model.pth'))
            
    print(f"âœ… {MODEL_NAME} è®­ç»ƒå®Œæˆï¼æœ€ä½³ Loss: {best_loss:.4f}")

if __name__ == '__main__':
    main()